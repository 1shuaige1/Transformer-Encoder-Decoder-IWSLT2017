# Transformer-Encoder-Decoder-IWSLT2017

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ª ä»é›¶æ„å»ºçš„ Transformer æ¨¡å‹ï¼ˆEncoder-Decoder æ¶æ„ï¼‰ï¼Œåœ¨ IWSLT2017 è‹±å¾·ç¿»è¯‘æ•°æ®é›†ï¼ˆenâ†’deï¼‰ ä¸Šè¿›è¡Œè®­ç»ƒä¸éªŒè¯ã€‚

---

## æ¨¡å‹æ¶æ„

æ¨¡å‹å®ç°äº†å®Œæ•´çš„ï¼š
- Multi-Head Self-Attention  
- Position-wise Feed Forward Network  
- Residual Connection + Layer Normalization  
- Sinusoidal æˆ– Learned ä½ç½®ç¼–ç   

é¡¹ç›®æ”¯æŒå‘½ä»¤è¡Œè¶…å‚é…ç½®ã€è‡ªåŠ¨ä¸‹è½½æ•°æ®é›†ã€ä¿å­˜æ¨¡å‹ä¸è®­ç»ƒéªŒè¯æ›²çº¿ã€‚

---

## ğŸ“‚ é¡¹ç›®ç»“æ„
```
Transformer-IWSLT2017/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ train.py # ä¸»è®­ç»ƒè„šæœ¬ï¼šå‚æ•°è§£æã€è®­ç»ƒå¾ªç¯ã€è¯„ä¼°
â”‚ â”œâ”€â”€ model.py # Transformer æ¨¡å‹å®šä¹‰ï¼ˆEncoder/Decoderï¼‰
â”‚ â””â”€â”€ data.py # æ•°æ®åŠ è½½ã€åˆ†è¯ã€æ‰¹å¤„ç†å°è£…
â”‚
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ run.sh # ä¸€é”®è®­ç»ƒè„šæœ¬ï¼ˆå«å®Œæ•´å‘½ä»¤è¡Œï¼‰
â”‚
â”œâ”€â”€ results/ # å­˜æ”¾è®­ç»ƒæ›²çº¿(loss_curve.png)ã€æ¨¡å‹æƒé‡(epochX.pt)
â”‚
â”œâ”€â”€ requirements.txt # ä¾èµ–åº“æ¸…å•
â””â”€â”€ README.md # æœ¬æ–‡ä»¶
```

---

## âš™ï¸ ç¯å¢ƒä¸ç¡¬ä»¶è¦æ±‚

| ç»„ä»¶ | æ¨èç‰ˆæœ¬ | è¯´æ˜ |
|------|-----------|------|
| Python | â‰¥ 3.9 | 3.9~3.11å‡å¯ |
| PyTorch | â‰¥ 2.0 | æ”¯æŒ CUDA |
| transformers | â‰¥ 4.44 | Hugging Face Tokenizer |
| datasets | â‰¥ 3.0 | è‡ªåŠ¨ä¸‹è½½ IWSLT2017 |
| GPU | RTX 3060 / A100 / T4 | æ¨èæ˜¾å­˜ â‰¥ 6GB |
| æ“ä½œç³»ç»Ÿ | Linux / Windows | å‡å¯è¿è¡Œ |

---

## ğŸ“¦ å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### requirements.txt å†…å®¹ï¼š 
```
torch>=2.0  
datasets>=3.0.0  
transformers>=4.44.0  
tqdm  
matplotlib  
numpy  
```

---

## è¿è¡Œæ–¹å¼

### æ–¹å¼ä¸€ï¼›ç›´æ¥è¿è¡Œè„šæœ¬
```
bash scripts/run.sh
```

### æ–¹å¼äºŒï¼šè¿è¡Œå‘½ä»¤
```
python src/train.py \
  --epochs 10 \
  --batch_size 64 \
  --d_model 256 \
  --n_heads 4 \
  --n_layers 2 \
  --d_ff 1024 \
  --dropout 0.1 \
  --lr 3e-4 \
  --max_len 128 \
  --seed 42 \
  --limit_train_samples 48880 \
  --device cuda \
  --save_dir results
```
---

## å®éªŒå¯å¤ç°æ€§
ä¸ºç¡®ä¿å®éªŒç»“æœå®Œå…¨å¯é‡å¤ï¼Œä»£ç ä¸­å›ºå®šäº†æ‰€æœ‰éšæœºç§å­ã€‚
```
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)
torch.cuda.manual_seed_all(42)
```
- æ•°æ®åŠ è½½ä¸åˆ’åˆ†ï¼šä½¿ç”¨ Hugging Face datasets æä¾›çš„å®˜æ–¹ IWSLT2017 (enâ†’de) ç‰ˆæœ¬
- Tokenizerï¼šHelsinki-NLP/opus-mt-en-de
- æ ·æœ¬æ•°é‡ï¼šlimit_train_samples = 48880
- éªŒè¯é›†ä½¿ç”¨å®˜æ–¹ validation split
- ä¼˜åŒ–å™¨ï¼šAdamW(lr=3e-4)
- Lossï¼šCrossEntropy(ignore_index=pad_id)
- Gradient Clipï¼šmax_norm=1.0

---

## ğŸ§ª ç¤ºä¾‹ç”¨æ³•

### 1. è®­ç»ƒæ¨¡å‹ï¼š
```bash
bash scripts/run_iwslt.sh
```
æ­¤è„šæœ¬å°†ï¼š
- ä½¿ç”¨é»˜è®¤å‚æ•°ï¼ˆd_model=256, num_layers=4, num_heads=8, epochs=20ï¼‰è®­ç»ƒæ¨¡å‹
- è‡ªåŠ¨ä¸‹è½½ IWSLT2017 è‹±å¾·æ•°æ®é›†
- è®­ç»ƒ 20 ä¸ª epoch å¹¶ä¿å­˜æ£€æŸ¥ç‚¹
- é»˜è®¤ä½¿ç”¨ GPU è¿›è¡Œè®­ç»ƒ

### 2. è¯„ä¼° BLEUï¼š
```bash
python -m src.eval_bleu --ckpt results/run_experiments/run_base/ckpt_epoch20.pt --split validation
```
å‚æ•°è¯´æ˜ï¼š
- `--ckpt`ï¼šæ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
- `--split`ï¼šè¯„ä¼°æ•°æ®é›†ï¼ˆvalidation/testï¼‰
- `--device`ï¼šè®¡ç®—è®¾å¤‡ï¼ˆcuda/cpuï¼Œé»˜è®¤ä¸ºcudaï¼‰

### 3. ç¿»è¯‘å¥å­ï¼š
```bash
python -m src.sample_mt --ckpt results/run_experiments/run_base/ckpt_epoch20.pt --sentence "Hello, how are you?"
```
å‚æ•°è¯´æ˜ï¼š
- `--ckpt`ï¼šæ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
- `--sentence`ï¼šå¾…ç¿»è¯‘çš„å¥å­
- `--device`ï¼šè®¡ç®—è®¾å¤‡ï¼ˆcuda/cpuï¼Œé»˜è®¤ä¸ºcudaï¼‰

### 4. è‡ªå®šä¹‰è®­ç»ƒå‚æ•°ï¼š
```bash
python -m src.train_mt --batch_size 64 --d_model 512 --num_layers 6 --epochs 20 --output_dir results/run_experiments/custom_run
```
å¸¸ç”¨å‚æ•°ï¼š
- `--batch_size`ï¼šæ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤64ï¼‰
- `--d_model`ï¼šæ¨¡å‹ç»´åº¦ï¼ˆé»˜è®¤256ï¼‰
- `--num_layers`ï¼šç¼–ç å™¨/è§£ç å™¨å±‚æ•°ï¼ˆé»˜è®¤4ï¼‰
- `--num_heads`ï¼šæ³¨æ„åŠ›å¤´æ•°ï¼ˆé»˜è®¤8ï¼‰
- `--d_ff`ï¼šå‰é¦ˆç½‘ç»œç»´åº¦ï¼ˆé»˜è®¤1024ï¼‰
- `--epochs`ï¼šè®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤20ï¼‰
- `--lr`ï¼šå­¦ä¹ ç‡ï¼ˆé»˜è®¤3e-4ï¼‰
- `--output_dir`ï¼šè¾“å‡ºç›®å½•è·¯å¾„

### 5. è¿è¡Œæ¶ˆèå®éªŒï¼š
```bash
# ç›¸å¯¹ä½ç½®åç½®æ¶ˆèå®éªŒ
python -m src.ablation.run_ablation_relpos

# ç»¼åˆæ¶ˆèå®éªŒ
python -m src.ablation.run_comprehensive_ablation_v2
```

---

## ğŸ” è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ

ä¸ºäº†æ¢ç©¶æ¨¡å‹æ€§èƒ½å¯¹å…³é”®è¶…å‚æ•°çš„æ•æ„Ÿç¨‹åº¦ï¼Œæˆ‘ä»¬å®ç°äº† `run_sensitivity.py` è„šæœ¬ï¼Œæ”¯æŒå¯¹å•ä¸€å˜é‡è¿›è¡Œæ‰¹é‡å®éªŒï¼Œå¹¶è®°å½• BLEU åˆ†æ•°ä¸éªŒè¯æŸå¤±ã€‚

### æ”¯æŒåˆ†æçš„å‚æ•°

| å‚æ•°å        | æµ‹è¯•èŒƒå›´              |
|---------------|-----------------------|
| `d_model`     | 128, 256, 512         |
| `num_layers`  | 2, 4, 6               |
| `batch_size`  | 32, 64, 128           |

### è¿è¡Œæ–¹æ³•

```bash
python -m src.run_sensitivity --param d_model --output_summary results/sensitivity_d_model.csv
```

### å®éªŒç»“æœ

#### d_model æ•æ„Ÿæ€§åˆ†æ
| d_model | BLEU  | Loss  |
|---------|-------|-------|
| 128     | 15.38 | 2.89  |
| 256     | 19.75 | 2.37  |
| 512     | 20.98 | 2.16  |

ç»“æœè¡¨æ˜ï¼Œéšç€æ¨¡å‹ç»´åº¦çš„å¢åŠ ï¼ŒBLEU åˆ†æ•°æå‡ä½†æå‡å¹…åº¦é€æ¸å‡å°ï¼ŒåŒæ—¶è®¡ç®—å¼€é”€æ˜¾è‘—å¢åŠ ã€‚

#### num_layers æ•æ„Ÿæ€§åˆ†æ
| num_layers | BLEU  | Loss  |
|------------|-------|-------|
| 2          | 15.95 | 2.79  |
| 4          | 19.75 | 2.37  |
| 6          | 20.85 | 2.24  |

å±‚æ•°å¢åŠ èƒ½æå‡æ€§èƒ½ï¼Œä½† 6 å±‚ç›¸æ¯” 4 å±‚çš„æå‡å¹…åº¦è¾ƒå°ï¼Œ4 å±‚åœ¨æ€§èƒ½å’Œæ•ˆç‡é—´å–å¾—äº†è¾ƒå¥½å¹³è¡¡ã€‚

#### batch_size æ•æ„Ÿæ€§åˆ†æ
| batch_size | BLEU  | Loss  |
|------------|-------|-------|
| 32         | 20.89 | 2.28  |
| 64         | 19.75 | 2.37  |

è¾ƒå°çš„æ‰¹å¤§å°ï¼ˆ32ï¼‰åœ¨æœ¬å®éªŒä¸­è¡¨ç°ç•¥å¥½ï¼Œå¯èƒ½ä¸æ¢¯åº¦æ›´æ–°é¢‘ç‡å’Œæ­£åˆ™åŒ–æ•ˆåº”æœ‰å…³ã€‚

### è¾“å‡ºç»“æœ

- æ¯æ¬¡å®éªŒçš„ç»“æœï¼ˆBLEUã€Lossï¼‰ä¼šä¿å­˜ä¸º `.csv` æ–‡ä»¶ã€‚
- è‡ªåŠ¨ç”Ÿæˆ BLEU ä¸ Loss éšå‚æ•°å˜åŒ–çš„è¶‹åŠ¿å›¾ã€‚

ç¤ºä¾‹å›¾è¡¨è·¯å¾„ï¼š
- `results/sensitivity_d_model.png`
- `results/sensitivity_num_layers.png`
- `results/sensitivity_batch_size.png`

### åˆ†æå»ºè®®

é€šè¿‡å¯¹æ¯”ä¸åŒå‚æ•°ä¸‹çš„ BLEU åˆ†æ•°ä¸æ”¶æ•›é€Ÿåº¦ï¼Œå¯ä»¥æ‰¾å‡ºæœ€ä¼˜æˆ–æ€§ä»·æ¯”æœ€é«˜çš„è¶…å‚ç»„åˆï¼Œè¾…åŠ©åç»­æ¨¡å‹ä¼˜åŒ–å†³ç­–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œd_model=512, num_layers=6 çš„é…ç½®è·å¾—æœ€ä½³æ€§èƒ½ï¼Œä½† d_model=256, num_layers=4 çš„é…ç½®åœ¨æ€§èƒ½å’Œæ•ˆç‡é—´å–å¾—äº†è‰¯å¥½å¹³è¡¡ã€‚

## ğŸ§ª æ¶ˆèå®éªŒ

æˆ‘ä»¬è¿›è¡Œäº†å…¨é¢çš„æ¶ˆèå®éªŒï¼Œä»¥è¯„ä¼°æ¨¡å‹å„ç»„ä»¶çš„é‡è¦æ€§ã€‚

### å®éªŒé…ç½®

| å®éªŒåç§° | ç›¸å¯¹ä½ç½®åç½® | Dropout | æ¿€æ´»å‡½æ•° | å±‚æ•° | BLEU  | Loss  |
|----------|--------------|---------|----------|------|-------|-------|
| åŸºçº¿æ¨¡å‹ | âœ“            | 0.1     | GELU     | 4    | 19.75 | 2.37  |
| ç§»é™¤ç›¸å¯¹ä½ç½®åç½® | âœ—        | 0.1     | GELU     | 4    | 11.17 | 3.07  |
| ç§»é™¤ Dropout | âœ“          | 0.0     | GELU     | 4    | 19.30 | 2.35  |
| æ›¿æ¢æ¿€æ´»å‡½æ•° | âœ“          | 0.1     | ReLU     | 4    | 19.14 | 2.47  |
| æµ…å±‚æ¨¡å‹   | âœ“            | 0.1     | GELU     | 2    | 15.95 | 2.79  |

### ç»“æœåˆ†æ

1. **ç›¸å¯¹ä½ç½®åç½®çš„é‡è¦æ€§**ï¼šç§»é™¤ç›¸å¯¹ä½ç½®åç½®å¯¼è‡´ BLEU åˆ†æ•°ä» 19.75 é™è‡³ 11.17ï¼ŒæŸå¤±å‡½æ•°ä» 2.37 å¢åŠ åˆ° 3.07ï¼Œè¡¨æ˜ç›¸å¯¹ä½ç½®ä¿¡æ¯å¯¹ç¿»è¯‘è´¨é‡è‡³å…³é‡è¦ã€‚

2. **Dropout çš„ä½œç”¨**ï¼šç§»é™¤ Dropout åæ€§èƒ½ç•¥æœ‰ä¸‹é™ï¼ˆ19.75 â†’ 19.30ï¼‰ï¼Œè¯´æ˜ Dropout åœ¨é˜²æ­¢è¿‡æ‹Ÿåˆæ–¹é¢æœ‰ä¸€å®šä½œç”¨ã€‚

3. **æ¿€æ´»å‡½æ•°å½±å“**ï¼šå°† GELU æ›¿æ¢ä¸º ReLU åæ€§èƒ½ç•¥æœ‰ä¸‹é™ï¼ˆ19.75 â†’ 19.14ï¼‰ï¼Œè¡¨æ˜ GELU æ¿€æ´»å‡½æ•°æ›´é€‚åˆæœ¬ä»»åŠ¡ã€‚

4. **æ¨¡å‹æ·±åº¦**ï¼šä» 4 å±‚å‡å°‘åˆ° 2 å±‚å¯¼è‡´æ˜¾è‘—æ€§èƒ½ä¸‹é™ï¼ˆ19.75 â†’ 15.95ï¼‰ï¼Œè¯æ˜äº†è¶³å¤Ÿæ¨¡å‹æ·±åº¦çš„é‡è¦æ€§ã€‚

å®éªŒç»“æœå……åˆ†éªŒè¯äº†ç›¸å¯¹ä½ç½®åç½®åœ¨ Transformer æ¨¡å‹ä¸­çš„å…³é”®ä½œç”¨ï¼Œå…¶å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“æœ€ä¸ºæ˜¾è‘—ã€‚
